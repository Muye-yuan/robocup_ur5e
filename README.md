# ğŸ† RoboCup UR5e Object Sorting System

[![License: MIT (Non-Commercial)](https://img.shields.io/badge/License-MIT%20(Non--Commercial)-blue.svg)](LICENSE)
[![ROS Version](https://img.shields.io/badge/ROS-Noetic-brightgreen.svg)](http://wiki.ros.org/noetic)
[![Python Version](https://img.shields.io/badge/Python-3.8-blue.svg)](https://www.python.org/)

**A modular ROS 1 Noetic system for YCB object sorting using UR5e robotic arm**

> **King's College London (KCL) - Robotics Group Project 2026**

---

## ğŸ“– Project Overview

This project implements an autonomous object sorting system for the RoboCup competition. The robot identifies YCB dataset objects, classifies them by color, computes optimal grasp poses, plans collision-free trajectories, and sorts objects into colored bins to maximize scores within a time limit.

**Key Features:**
- ğŸ¯ **Finite State Machine (FSM)** for robust task orchestration
- ğŸ‘ï¸ **YOLOv8 Object Detection** with YCB dataset integration
- ğŸ¤ **GraspNet Grasp Estimation** for reliable grasping
- ğŸ›¤ï¸ **Path Planning & Collision Avoidance** with MoveIt
- ğŸ¤– **IK/FK Motion Control** for UR5e manipulator
- ğŸ³ **Dockerized Architecture** for cross-platform development
- âš¡ **CUDA Support** for GPU-accelerated perception (CUDA 11.3 & 12.0)

---

## ğŸ‘¥ Team Members & Responsibilities

| Team Member | Role | Package | Responsibilities |
|-------------|------|---------|------------------|
| **Suhang Xia** | System Architect & FSM | `robocup_brain` | System architecture, FSM implementation, object scoring algorithm, subsystem integration, error recovery |
| **Jiaxin Liang** | Motion Control | `motion_control` | Forward/Inverse kinematics, dynamics, trajectory generation, low-level motion execution |
| **Sarvin & Chang Gao** | Path Planning | `path_planning` | Collision-free path planning, obstacle avoidance, trajectory optimization, MoveIt integration |
| **Fazhan & Ruiyi** | Object Detection | `perception_yolo` | YOLOv8 detection, YCB classification, color recognition, 3D localization, score assignment |
| **Muye Yuan** | Grasp Estimation | `perception_grasp` | GraspNet integration, point cloud processing, grasp quality evaluation, object segmentation |

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      ROBOCUP_BRAIN (FSM)                             â”‚
â”‚                   Suhang Xia - Architect                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ SEARCH â”‚â”€â–¶â”‚ DETECT â”‚â”€â–¶â”‚ SCORE â”‚â”€â–¶â”‚ GRASP â”‚â”€â–¶â”‚ PLACE  â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”                                       â”‚
â”‚                   â”‚ RECOVERY â”‚ (Error Handling)                      â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                                â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
       â”‚  PERCEPTION  â”‚                â”‚    MOTION    â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                                â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚                    â”‚         â”‚                          â”‚
â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”  â”Œâ”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”
â”‚   YOLO    â”‚  â”‚   GRASP    â”‚  â”‚   PATH   â”‚    â”‚   MOTION    â”‚
â”‚ Detection â”‚  â”‚ Estimation â”‚  â”‚ PLANNING â”‚    â”‚  CONTROL    â”‚
â”‚ (CUDA 12) â”‚  â”‚ (CUDA 11.3)â”‚  â”‚          â”‚    â”‚   (IK/FK)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### For Team Members

1. **Read the setup guide**: [`docs/SETUP_GUIDE.md`](docs/SETUP_GUIDE.md) - Platform-specific instructions (Ubuntu/WSL2/Mac)
2. **Read the team guide**: [`docs/TEAM_README.md`](docs/TEAM_README.md) - Your specific tasks and interfaces
3. **Download models**: Run `./scripts/download_models.sh` to get YOLO and GraspNet weights
4. **Find your TODOs**: Search for `TODO` comments in your assigned file
5. **Start developing**: Edit code, restart containers, test, commit!

### Quick Commands

```bash
# Clone repository
git clone https://github.com/your-username/robocup_ur5e.git
cd robocup_ur5e

# Download required models (first time only)
./scripts/download_models.sh

# Build Docker images (first time only, 30-60 min)
./scripts/rebuild_all.sh

# Start all services
./scripts/start.sh

# Check system status
./scripts/status.sh

# View logs
docker-compose logs -f
```

---

## ğŸ“¦ Project Structure

```
robocup_ur5e/
â”œâ”€â”€ src/                      # ROS packages
â”‚   â”œâ”€â”€ common_msgs/          # Shared message definitions
â”‚   â”œâ”€â”€ robocup_brain/        # FSM orchestration (Suhang)
â”‚   â”œâ”€â”€ motion_control/       # IK/FK/Dynamics (Jiaxin)
â”‚   â”œâ”€â”€ path_planning/        # Path planning (Sarvin & Chang)
â”‚   â”œâ”€â”€ perception_yolo/      # Object detection (Fazhan & Ruiyi)
â”‚   â””â”€â”€ perception_grasp/     # Grasp estimation (Muye)
â”œâ”€â”€ docker/                   # Docker configurations
â”œâ”€â”€ docs/                     # ğŸ“š All documentation
â”‚   â”œâ”€â”€ SETUP_GUIDE.md        # â­ Platform setup
â”‚   â”œâ”€â”€ TEAM_README.md        # â­ Team tasks
â”‚   â””â”€â”€ MODELS_AND_DATASETS.md # â­ Model downloads
â”œâ”€â”€ scripts/                  # ğŸ”§ System scripts
â”‚   â”œâ”€â”€ start.sh              # Start system
â”‚   â”œâ”€â”€ rebuild_all.sh        # Build images
â”‚   â””â”€â”€ download_models.sh    # Download weights
â”œâ”€â”€ weights/                  # ğŸ¤– Model weights (Git LFS / Hugging Face)
â”‚   â”œâ”€â”€ yolo/                 # YOLO detection models
â”‚   â””â”€â”€ graspnet/             # GraspNet checkpoints
â””â”€â”€ data/                     # ğŸ“Š Datasets (Hugging Face)
    â”œâ”€â”€ datasets/             # Training data
    â””â”€â”€ ycb_objects/          # YCB object models
```

---

## ğŸ”„ ROS Topics

**Perception:**
- `/perception/detected_objects` - Detected YCB objects with scores
- `/perception/grasp_candidates` - Computed grasp poses

**Decision:**
- `/brain/task_decision` - Current FSM state and target
- `/brain/motion_request` - Motion commands

**Motion:**
- `/planning/trajectory` - Planned collision-free trajectories
- `/motion/command` - Low-level motion commands
- `/motion/result` - Execution results

---

## ğŸ› ï¸ Technology Stack

- **ROS**: ROS 1 Noetic
- **Perception**: YOLOv8 (CUDA 12.0), GraspNet-1Billion (CUDA 11.3)
- **Planning**: MoveIt, OMPL (RRT/RRT*)
- **Control**: UR5e IK/FK, Trajectory Generation
- **Libraries**: PyTorch, OpenCV, Open3D, py_trees_ros
- **Deployment**: Docker, Docker Compose, NVIDIA Container Runtime

---

## ğŸ“š Documentation

| Document | Purpose |
|----------|---------|
| **[docs/SETUP_GUIDE.md](docs/SETUP_GUIDE.md)** â­ | Platform-specific setup (Ubuntu/WSL2/Mac) |
| **[docs/TEAM_README.md](docs/TEAM_README.md)** â­ | Team member tasks and interfaces |
| **[docs/MODELS_AND_DATASETS.md](docs/MODELS_AND_DATASETS.md)** â­ | Model weights and dataset downloads |
| **[docs/CONTRIBUTING.md](docs/CONTRIBUTING.md)** | Development guidelines |
| **[docs/DEPENDENCIES.md](docs/DEPENDENCIES.md)** | Version compatibility |
| **[scripts/README.md](scripts/README.md)** | Script documentation |

---

## ğŸ“ Academic Use

### Citation

If you use this system in your research or reference it in publications, please cite this repository:

```bibtex
@misc{robocup_ur5e_kcl_2026,
  author = {Suhang Xia and Jiaxin Liang and Sarvin and Chang Gao and Fazhan and Ruiyi and Muye Yuan},
  title = {RoboCup UR5e Object Sorting System},
  year = {2026},
  publisher = {King's College London},
  howpublished = {\url{https://github.com/your-username/robocup_ur5e}},
  note = {RoboCup Competition - YCB Object Sorting}
}
```

### Acknowledgments

This project was developed as part of the Robotics course at **King's College London (KCL)** in 2026. We thank:
- **Suhang Xia** - System architecture and FSM design
- **Jiaxin Liang** - Motion control and kinematics
- **Sarvin & Chang Gao** - Path planning and collision avoidance
- **Fazhan & Ruiyi** - Computer vision and object detection
- **Muye Yuan** - Grasp pose estimation
- All KCL faculty and staff who supported this project

---

## ğŸ“œ License

**MIT License (Non-Commercial Use Only)**

Copyright (c) 2026 King's College London - Robotics Team

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction for **non-commercial purposes only**, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, subject to the following conditions:

**The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.**

**THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.**

### âš ï¸ Non-Commercial Use Only

This software is licensed for **academic and research purposes only**. **Commercial use is strictly prohibited** without explicit written permission from the authors.


---

## ğŸ¤ Contributing

This is a group project for KCL. Team members should read [`CONTRIBUTING.md`](CONTRIBUTING.md) and follow the development workflow outlined in [`TEAM_README.md`](TEAM_README.md).

---

## ğŸ› Issue Reporting

Found a bug? Please open an issue with:
- Description of the problem
- Steps to reproduce
- Expected vs actual behavior
- System information (OS, GPU, Docker version)

---

## ğŸ“ Contact

- **Project Lead**: Suhang Xia - suhang.xia@kcl.ac.uk
- **GitHub Issues**: [Report bugs or request features](https://github.com/your-username/robocup_ur5e/issues)

---

## ğŸ† Competition Information

**Event**: RoboCup 2026 - Object Sorting Challenge  
**Task**: YCB Object Sorting by Color  
**Robot**: Universal Robots UR5e  
**Institution**: King's College London (KCL)

---

**Built with â¤ï¸ by the KCL Robotics Team**

*Last Updated: January 26, 2026*
